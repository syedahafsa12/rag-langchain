# ğŸ“– RAG-Powered Chatbot with FAISS & Gemini AI
![image](https://github.com/user-attachments/assets/55a70bc5-211f-46ae-ba01-04428e7feb8f)

## ğŸš€ Overview
This project implements a Retrieval-Augmented Generation (RAG) chatbot using FAISS (Facebook AI Similarity Search) for vector storage and Google Gemini AI for LLM responses. It allows users to upload PDFs, extract content, generate embeddings, and ask AI-powered questions based on the document.

âœ… Tech Stack:

LangChain (for orchestration)
FAISS (for vector storage)
Google Gemini AI (for embeddings & responses)
Streamlit (for the frontend UI)
PyPDFLoader (for extracting PDF text)


ğŸ¯ Features
âœ… Upload a PDF document
âœ… AI extracts & indexes the content
âœ… Ask questions based on the PDF
âœ… AI responds using RAG (Retrieval-Augmented Generation)
âœ… Uses FAISS for fast vector similarity search

ğŸ›  How It Works
1ï¸âƒ£ User uploads a PDF
2ï¸âƒ£ Text is extracted from the PDF using PyPDFLoader
3ï¸âƒ£ Text is split into chunks using RecursiveCharacterTextSplitter
4ï¸âƒ£ Embeddings are generated using Google Gemini AI
5ï¸âƒ£ FAISS stores the embeddings as a vector database
6ï¸âƒ£ User asks a question, and the chatbot retrieves relevant context using FAISS
7ï¸âƒ£ Google Gemini AI generates a response based on the retrieved context
8ï¸âƒ£ AI responds with helpful answers & references

ğŸ–¥ Live Demo
ğŸš€ Try it here: hafsa-rag-project.streamlit.app
